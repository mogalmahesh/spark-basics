{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Aggregation Functions\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df = spark.read\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .csv(\"D:\\\\code\\\\spark\\\\spark-basics\\\\data\\\\flight-data\\\\csv\")\n",
    "flights_df.registerTempTable(\"flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1506"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "flights_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+\n|count(1)|\n+--------+\n|    1506|\n+--------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from flights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------------+\n|count(DEST_COUNTRY_NAME)|\n+------------------------+\n|                    1506|\n+------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "flights_df.select(count(\"DEST_COUNTRY_NAME\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------+\n|dest_countries|\n+--------------+\n|           170|\n+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "flights_df.select( \\\n",
    "    countDistinct(\"DEST_COUNTRY_NAME\")\\\n",
    "    .alias(\"dest_countries\"))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------+\n|dest_countries|\n+--------------+\n|           170|\n+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select \n",
    "count(distinct DEST_COUNTRY_NAME) as dest_countries\n",
    "from flights\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------------+\n|approx countries|\n+----------------+\n|             164|\n+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import approx_count_distinct\n",
    "flights_df.select (\\\n",
    "    approx_count_distinct(\"DEST_COUNTRY_NAME\")\\\n",
    "    .alias(\"approx countries\"))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------------+\n|approx countries|\n+----------------+\n|             163|\n+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "flights_df.select (\\\n",
    "    approx_count_distinct(\"DEST_COUNTRY_NAME\", 0.15)\\\n",
    "    .alias(\"approx countries\"))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------------+\n|approx countries|\n+----------------+\n|             160|\n+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "flights_df.select (\\\n",
    "    approx_count_distinct(\"DEST_COUNTRY_NAME\",0.25)\\\n",
    "    .alias(\"approx countries\"))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------------+\n|approx_countries|\n+----------------+\n|             162|\n+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT approx_count_distinct(DEST_COUNTRY_NAME,0.1)\n",
    "as approx_countries\n",
    "FROM flights\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------------+-----------------------+\n|first(DEST_COUNTRY_NAME)|last(DEST_COUNTRY_NAME)|\n+------------------------+-----------------------+\n|           United States|                      b|\n+------------------------+-----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import first, last\n",
    "flights_df.select(\\\n",
    "    first(\"DEST_COUNTRY_NAME\"),\n",
    "    last(\"DEST_COUNTRY_NAME\"))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_df = spark.read\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .csv(\"D:\\\\code\\\\spark\\\\spark-basics\\\\data\\\\flight-data\\\\csv\\\\2010-summary.csv\")\n",
    "flights_df.registerTempTable(\"flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+----------+\n|min(count)|max(count)|\n+----------+----------+\n|         1|    348113|\n+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, max\n",
    "flights_df.select(\\\n",
    "    min(\"count\"),\n",
    "    max(\"count\"))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+----------+\n|min(count)|max(count)|\n+----------+----------+\n|         1|    348113|\n+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select min(count),max(count) from flights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+\n|sum(count)|\n+----------+\n|    422269|\n+----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "flights_df.select(sum(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+\n|sum(count)|\n+----------+\n|    422269|\n+----------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select sum(count) from flights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------------+\n|sum(DISTINCT count)|\n+-------------------+\n|             419432|\n+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sumDistinct\n",
    "flights_df.select(sumDistinct(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------+\n|       avg(count)|\n+-----------------+\n|1655.956862745098|\n+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "flights_df.select(avg(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------+\n|       avg(count)|\n+-----------------+\n|1655.956862745098|\n+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select avg(count) from flights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------------------------+------------------------------+\n|collect_list(DEST_COUNTRY_NAME)|collect_set(DEST_COUNTRY_NAME)|\n+-------------------------------+------------------------------+\n|           [United States, U...|          [Italy, Slovakia,...|\n+-------------------------------+------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_list, collect_set\n",
    "flights_df.select(\\\n",
    "    collect_list(\"DEST_COUNTRY_NAME\"),\n",
    "    collect_set(\"DEST_COUNTRY_NAME\"))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------------------+-------------------------------+\n|collect_set(DEST_COUNTRY_NAME)|collect_list(DEST_COUNTRY_NAME)|\n+------------------------------+-------------------------------+\n|          [Italy, Slovakia,...|           [United States, U...|\n+------------------------------+-------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select \n",
    "collect_Set(DEST_COUNTRY_NAME), \n",
    "collect_list(DEST_COUNTRY_NAME) \n",
    "from flights\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------+-----+\n|DEST_COUNTRY_NAME|count|\n+-----------------+-----+\n|         Anguilla|    1|\n|           Russia|    1|\n|         Paraguay|    1|\n|          Senegal|    1|\n|           Sweden|    1|\n+-----------------+-----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "flights_df.groupBy(\"DEST_COUNTRY_NAME\").count().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------+--------+\n|DEST_COUNTRY_NAME|count(1)|\n+-----------------+--------+\n|         Anguilla|       1|\n|           Russia|       1|\n|         Paraguay|       1|\n|          Senegal|       1|\n|           Sweden|       1|\n+-----------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select DEST_COUNTRY_NAME, count(*) from \n",
    "flights group by DEST_COUNTRY_NAME \n",
    "limit 5\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------+----------+\n|DEST_COUNTRY_NAME|avg(count)|\n+-----------------+----------+\n|         Anguilla|      21.0|\n|           Russia|     152.0|\n|         Paraguay|      90.0|\n|          Senegal|      29.0|\n|           Sweden|      65.0|\n+-----------------+----------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "flights_df.groupBy(\"DEST_COUNTRY_NAME\").avg(\"count\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}